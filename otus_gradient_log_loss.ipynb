{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1./(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(t, y):\n",
    "    return np.sum((-t*np.log(y) - (1 - t) * (np.log(1 - y))), keepdims=True).flatten()\n",
    "\n",
    "def diff_log_loss(t, y):\n",
    "    return np.sum((t-y)*x, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logos(sample):\n",
    "    sigmoid(sample.dot(w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer: #слой реализован в виде класса\n",
    "  \n",
    "    \n",
    "    def __init__(self, n_inp, n_out, lr=0.1):\n",
    "        self.shape = (n_inp, n_out) #залетают входящие и выходящие значения\n",
    "        self.lr = lr #шаг обучения\n",
    "        self.w = np.zeros(self.shape, dtype=np.float32) #веса в начале заданы нулями\n",
    "        self.b = np.zeros((1, n_out), dtype=np.float32) #смещения в начале заданы нулями\n",
    "        self._clear_grads() #проход обычного градиентного спуска\n",
    "\n",
    "    def _clear_grads(self): #градиентный спуск\n",
    "        self.inp = None\n",
    "        self.activations = None\n",
    "        self.d_sigma = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def __call__(self, x): #вызов класса\n",
    "        if len(x.shape) == 1: #если входящие значения одноразмерны - сменить размерность\n",
    "            x = x.reshape(1, -1)\n",
    "        self.inp = x #задаем входные значения\n",
    "        self.activations = sigmoid(x.dot(self.w) + self.b) #запуск функции с функцией активации\n",
    "        return self.activations\n",
    "\n",
    "    def backward(self, grad): # обратный проход\n",
    "        self.d_sigma = self.activations * (1 - self.activations) #производная функции ошибки \n",
    "        self.d_w = self.grad_w(grad)\n",
    "        self.d_b = self.grad_b(grad)\n",
    "        return self.grad_x(grad)\n",
    "\n",
    "    def grad_w(self, grad):\n",
    "        return grad * self.inp.T * self.d_sigma\n",
    "\n",
    "    def grad_b(self, grad):\n",
    "        return grad * self.d_sigma\n",
    "\n",
    "    def grad_x(self, grad):\n",
    "        return self.w.dot(grad) * self.d_sigma\n",
    "\n",
    "    def step(self):\n",
    "        self.w -= self.d_w * self.lr\n",
    "        self.b -= self.d_b * self.lr\n",
    "        self._clear_grads()\n",
    "        #return(self.w, self.b)\n",
    "    \n",
    "    def logos(self,sample):\n",
    "        return(sigmoid(sample.dot(self.w) + self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = Layer(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0 = np.random.normal(loc=(-1, -1), scale=(1, 1))\n",
    "mu_1 = np.random.normal(loc=(1, 1), scale=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.25465211, -0.57366029])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.56558939,  0.67500025])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = mu_0\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    y = l1(x)\n",
    "    #if i % 100 == 0:\n",
    "        #print(f'{log_loss(t, y)} + {diff_log_loss(t, y)}')\n",
    "    d_y = diff_log_loss(t, y)\n",
    "    l1.backward(d_y)\n",
    "    l1.step()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0099028]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00995216])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.array([1])\n",
    "x1 = mu_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10145966] + [[-0.17639991]]\n",
      "[0.08190877] + [[-0.14378578]]\n",
      "[0.07020206] + [[-0.12394964]]\n",
      "[0.06225133] + [[-0.1103447]]\n",
      "[0.05642265] + [[-0.10030197]]\n",
      "[0.05192463] + [[-0.09251185]]\n",
      "[0.04832327] + [[-0.08624932]]\n",
      "[0.04535873] + [[-0.08107724]]\n",
      "[0.04286509] + [[-0.07671483]]\n",
      "[0.04073092] + [[-0.07297264]]\n",
      "[0.03887828] + [[-0.06971761]]\n",
      "[0.03725089] + [[-0.06685336]]\n",
      "[0.03580699] + [[-0.06430816]]\n",
      "[0.03451483] + [[-0.0620273]]\n",
      "[0.0333498] + [[-0.05996832]]\n",
      "[0.03229249] + [[-0.05809766]]\n",
      "[0.03132752] + [[-0.05638862]]\n",
      "[0.03044223] + [[-0.05481926]]\n",
      "[0.02962635] + [[-0.05337172]]\n",
      "[0.02887132] + [[-0.05203108]]\n",
      "[0.02817] + [[-0.0507849]]\n",
      "[0.02751635] + [[-0.04962263]]\n",
      "[0.02690529] + [[-0.04853542]]\n",
      "[0.0263324] + [[-0.04751551]]\n",
      "[0.02579388] + [[-0.04655626]]\n",
      "[0.02528647] + [[-0.04565195]]\n",
      "[0.02480729] + [[-0.04479753]]\n",
      "[0.02435387] + [[-0.04398866]]\n",
      "[0.02392398] + [[-0.04322143]]\n",
      "[0.02351565] + [[-0.04249238]]\n",
      "[0.02312717] + [[-0.0417985]]\n",
      "[0.02275699] + [[-0.04113704]]\n",
      "[0.02240372] + [[-0.04050558]]\n",
      "[0.02206613] + [[-0.03990191]]\n",
      "[0.02174311] + [[-0.03932414]]\n",
      "[0.02143364] + [[-0.0387704]]\n",
      "[0.02113678] + [[-0.03823908]]\n",
      "[0.02085173] + [[-0.03772875]]\n",
      "[0.02057771] + [[-0.03723803]]\n",
      "[0.02031404] + [[-0.03676571]]\n",
      "[0.02006012] + [[-0.03631076]]\n",
      "[0.01981533] + [[-0.03587203]]\n",
      "[0.01957914] + [[-0.03544862]]\n",
      "[0.01935109] + [[-0.03503971]]\n",
      "[0.0191307] + [[-0.03464444]]\n",
      "[0.01891755] + [[-0.0342621]]\n",
      "[0.01871127] + [[-0.03389197]]\n",
      "[0.01851146] + [[-0.03353341]]\n",
      "[0.01831789] + [[-0.03318595]]\n",
      "[0.01813016] + [[-0.03284893]]\n",
      "[0.01794796] + [[-0.03252176]]\n",
      "[0.01777113] + [[-0.03220418]]\n",
      "[0.0175993] + [[-0.03189552]]\n",
      "[0.01743234] + [[-0.03159558]]\n",
      "[0.01726992] + [[-0.03130373]]\n",
      "[0.01711195] + [[-0.03101983]]\n",
      "[0.01695816] + [[-0.03074341]]\n",
      "[0.01680837] + [[-0.03047413]]\n",
      "[0.01666241] + [[-0.03021169]]\n",
      "[0.01652019] + [[-0.02995594]]\n",
      "[0.01638149] + [[-0.0297065]]\n",
      "[0.01624618] + [[-0.0294631]]\n",
      "[0.01611411] + [[-0.02922553]]\n",
      "[0.01598518] + [[-0.02899355]]\n",
      "[0.01585925] + [[-0.02876694]]\n",
      "[0.01573621] + [[-0.02854552]]\n",
      "[0.01561595] + [[-0.02832906]]\n",
      "[0.01549836] + [[-0.0281174]]\n",
      "[0.01538335] + [[-0.02791035]]\n",
      "[0.01527084] + [[-0.02770776]]\n",
      "[0.01516078] + [[-0.02750957]]\n",
      "[0.01505302] + [[-0.02731551]]\n",
      "[0.01494747] + [[-0.02712542]]\n",
      "[0.01484406] + [[-0.02693915]]\n",
      "[0.01474277] + [[-0.02675668]]\n",
      "[0.01464355] + [[-0.02657791]]\n",
      "[0.01454623] + [[-0.02640256]]\n",
      "[0.01445074] + [[-0.02623049]]\n",
      "[0.01435723] + [[-0.02606196]]\n",
      "[0.01426541] + [[-0.02589647]]\n",
      "[0.01417525] + [[-0.02573397]]\n",
      "[0.0140869] + [[-0.0255747]]\n",
      "[0.01400005] + [[-0.02541812]]\n",
      "[0.01391482] + [[-0.02526446]]\n",
      "[0.01383111] + [[-0.02511352]]\n",
      "[0.01374881] + [[-0.02496511]]\n",
      "[0.01366807] + [[-0.02481949]]\n",
      "[0.01358855] + [[-0.02467607]]\n",
      "[0.01351058] + [[-0.02453544]]\n",
      "[0.01343373] + [[-0.02439682]]\n",
      "[0.01335835] + [[-0.02426084]]\n",
      "[0.01328403] + [[-0.02412675]]\n",
      "[0.01321111] + [[-0.02399519]]\n",
      "[0.01313918] + [[-0.02386539]]\n",
      "[0.01306858] + [[-0.02373801]]\n",
      "[0.01299894] + [[-0.02361232]]\n",
      "[0.01293051] + [[-0.02348883]]\n",
      "[0.01286306] + [[-0.02336709]]\n",
      "[0.01279665] + [[-0.02324721]]\n",
      "[0.01273131] + [[-0.02312926]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    y = l1(x1)\n",
    "    #if i % 100 == 0:\n",
    "        #print(f'{log_loss(t1, y)} + {diff_log_loss(t1, y)}')\n",
    "    d_y = diff_log_loss(t1, y)\n",
    "    l1.backward(d_y)\n",
    "    l1.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
