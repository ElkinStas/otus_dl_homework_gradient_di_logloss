{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('Fish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### постараемся предсказать вес рыбы по другим параметрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Weight'].values\n",
    "x = dataset[['Length1','Length2', 'Length3','Height','Width']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### нормализуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x - x.mean()) / x.std()\n",
    "y = (y - y.mean()) / y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27., 32., 13., 18.,  6.,  6., 12.,  6., 12.,  4.,  5.,  6.,  6.,\n",
       "         2.,  0.,  1.,  0.,  0.,  1.,  2.]),\n",
       " array([-1.1162267 , -0.88503765, -0.65384861, -0.42265957, -0.19147053,\n",
       "         0.03971852,  0.27090756,  0.5020966 ,  0.73328564,  0.96447468,\n",
       "         1.19566373,  1.42685277,  1.65804181,  1.88923085,  2.1204199 ,\n",
       "         2.35160894,  2.58279798,  2.81398702,  3.04517606,  3.27636511,\n",
       "         3.50755415]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "Данные нужно разделить в отношении 80/20 на обучающую и валидационную выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = int(len(y) * 0.8)\n",
    "index = np.arange(len(dataset))\n",
    "np.random.shuffle(index)\n",
    "\n",
    "train_index, val_index = index[:pivot], index[pivot:]\n",
    "\n",
    "y_train, y_val = y[train_index], y[val_index]\n",
    "x_train, x_val = x[train_index], x[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация\n",
    "\n",
    "Воспользуйтесь x.shape, чтобы задать правильную размерность вектора с параметрами. Проинициализируйте его случайными значениями.\n",
    "\n",
    "**Значение сдвига** `b = 0`; часто сдвиг или вектор сдвигов инициализируют нулями или средним по выборке значением, если оно отлично от нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_value = tf.random.normal(shape=(5,))\n",
    "w = initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = tf.Variable\n",
    "#initial_value = np.array([random.randint(0,100) for i in range(5)])\n",
    "#w = initial_value.astype('float32')\n",
    "b = tf.Variable(0, dtype=tf.float32)\n",
    "learning_rate = tf.constant(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, w, threshold=0.001, n_steps=10000):\n",
    "  x = tf.constant(x, dtype=tf.float32)\n",
    "  y = tf.constant(y, dtype=tf.float32)\n",
    "\n",
    "  for step in range(n_steps):\n",
    "    loss = train_step(x, y, w)\n",
    "    if loss < threshold:\n",
    "      break\n",
    "    if (step + 1) % 50 == 0:\n",
    "      print(f\"Loss at {step} iter. is {loss.numpy()}\")\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step\n",
    "\n",
    "Дополните `train_step` так, чтобы функция вычисляла значение $\\hat{y}$ для переданного $x$, и затем значение функции ошибки с помощью функции `calc_loss`.\n",
    "\n",
    "Добавитье обновление параметров в строчке `w = ...`. *Если возвращаемое значение* функции ошибки равно `nan` или `inf`, подумайте, что могло привести к такой ситуации и что нужно исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y, w):\n",
    "    with tf.GradientTape() as tape:\n",
    "    \n",
    "    #print(f'{x.dtype} + {w.dtype}')\n",
    "        y_hat = tf.tensordot(x, w, 1)\n",
    "        loss = calc_loss(y, y_hat)\n",
    "        print(loss)\n",
    "        grads = tape.gradient(loss, w)\n",
    "        print(grads)\n",
    "    \n",
    "    w = w - grads\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножение вектора на вектор или вектора на строку в `tf` - это сложная операция. В отличие от матричного умножения, которое можно записать просто как `C = A @ B` или `C = tf.matmul(A, B)`, здесь нужно вызывать функцию `tf.tensordot`, которая способна умножать тензоры любой размерности. Затем функции надо указать ось, по которой выполняется сложение: в данном случае, 1 - т.е. для произведения матрицы на вектор нужно выполнить операцию\n",
    "\n",
    "`tf.tensordot(x, w, 1)`\n",
    "\n",
    "Воспользовавшись этим способом, напишите модель для линейной регрессии. Кстати, это не единственный возможный вариант [расчета скалярного произведения в tensorflow](https://stackoverflow.com/questions/40670370/dot-product-of-two-vectors-in-tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию, которая вычисляет значение MSE для двух переданных векторов со значениями $y, \\hat{y}$ (истинные и спрогнозированные значения). Функция должна возвращать _одно_ значение (скаляр), как и в формуле $\\frac{1}{n}\\sum_{i=1}^{n}(y^{(i)} - \\hat{y}^{(i)})^2$ \n",
    "\n",
    "* разность векторов и возведение в квадрат можно сделать при помощи обычных операторов `-`, `**2`\n",
    "* Для того, чтобы в тензорфлоу выполнить аналог операции $\\frac{1}{n}\\sum_{i=1}^n (...)$, воспользуйтесь функцией `tf.reduce_mean`. Заодно можете изучить, какие еще есть `tf.reduce_...` функции :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(y, y_hat):\n",
    "    x = tf.reduce_mean(y - y_hat)**2\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29774487,  0.46298639,  0.81502268, -0.52989962, -1.11718236])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zu = x\n",
    "zu.reshape(159,5)\n",
    "zu[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.258624, shape=(), dtype=float32)\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-355-761683cc9096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-349-2a6f2d7d1828>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(x, y, w, threshold, n_steps)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-350-b7f1403dabbc>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, y, w)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m           y = ops.convert_to_tensor_v2(\n\u001b[0;32m--> 903\u001b[0;31m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "fit(zu[1], y_train, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
